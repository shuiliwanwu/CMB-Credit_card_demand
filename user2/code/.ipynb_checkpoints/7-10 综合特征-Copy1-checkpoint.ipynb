{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "feature1_path = '../final_feature/day_click_count.csv'\n",
    "feature2_path = '../final_feature/day_statical.csv'\n",
    "\n",
    "feature3_path = '../final_feature/evt_lbl_click_count.csv'\n",
    "feature4_path = '../final_feature/hour_statical.csv'\n",
    "\n",
    "feature5_path = '../final_feature/minute_statical.csv'\n",
    "feature6_path = '../final_feature/weekday_click_count.csv'\n",
    "\n",
    "feature1=pd.read_csv(feature1_path,sep='\\t')\n",
    "feature2=pd.read_csv(feature2_path,sep='\\t')\n",
    "feature3=pd.read_csv(feature3_path,sep='\\t')\n",
    "feature4=pd.read_csv(feature4_path,sep='\\t')\n",
    "feature5=pd.read_csv(feature5_path,sep='\\t')\n",
    "feature6=pd.read_csv(feature6_path,sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_agg_filename = r'../train/train_agg.csv'\n",
    "train_flg_filename = r'../train/train_flg.csv'\n",
    "\n",
    "test_agg_filename = r'../test/test_agg.csv'\n",
    "test_flg_filename = r'../test/submit_sample.csv'\n",
    "\n",
    "train_agg=pd.read_csv(train_agg_filename,sep='\\t')\n",
    "test_agg=pd.read_csv(test_agg_filename,sep='\\t')\n",
    "\n",
    "agg=pd.concat([train_agg,test_agg])\n",
    "\n",
    "train_flg = pd.read_csv(train_flg_filename,sep='\\t')\n",
    "test_flg = pd.read_csv(test_flg_filename,sep='\\t')\n",
    "test_flg['FLAG'] = -1\n",
    "del test_flg['RST']\n",
    "flg = pd.concat([train_flg,test_flg],copy=False)\n",
    "\n",
    "data = pd.merge(agg,flg,on=['USRID'],how='left',copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.merge(data,feature1,how='left')\n",
    "data=pd.merge(data,feature2,how='left')\n",
    "data=pd.merge(data,feature3,how='left')\n",
    "data=pd.merge(data,feature4,how='left')\n",
    "data=pd.merge(data,feature5,how='left')\n",
    "data=pd.merge(data,feature6,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "evt_one_hot = pd.read_csv('../final_feature/final_feature.csv',sep='\\t')\n",
    "data = pd.merge(data,evt_one_hot,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data1= pd.read_csv('../final_feature/lbl_one_shift.csv',sep='\\t')\n",
    "data=pd.merge(data,data1,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USRID</th>\n",
       "      <th>dist_41_min</th>\n",
       "      <th>dist_41_max</th>\n",
       "      <th>dist_41_std</th>\n",
       "      <th>dist_41_mean</th>\n",
       "      <th>promote1</th>\n",
       "      <th>promote2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>29</td>\n",
       "      <td>9.797959</td>\n",
       "      <td>14.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>7.505553</td>\n",
       "      <td>19.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>7.092249</td>\n",
       "      <td>11.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   USRID  dist_41_min  dist_41_max  dist_41_std  dist_41_mean  promote1  \\\n",
       "0      2           18           19     0.707107     18.500000         0   \n",
       "1      3            4           29     9.797959     14.666667         0   \n",
       "2      4           12           12          NaN     12.000000         0   \n",
       "3      5           12           27     7.505553     19.333333         0   \n",
       "4      7            4           23     7.092249     11.600000         0   \n",
       "\n",
       "   promote2  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#加上day_dist_promote\n",
    "feature7=pd.read_csv('../final_feature/day_dist_promote.csv')\n",
    "feature7.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature7.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(-1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(data,feature7,how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['FLAG']!=-1]\n",
    "test = data[data['FLAG']==-1]\n",
    "data.fillna(-1,inplace=True)\n",
    "from feature_selector import FeatureSelector\n",
    "fs = FeatureSelector(data = train.drop(['FLAG','USRID'],axis=1), labels = train['FLAG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 features with a correlation magnitude greater than 0.98.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs.identify_collinear(correlation_threshold = 0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 625)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting Model\n",
      "\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.858004\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's auc: 0.853306\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.835557\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.86081\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.867262\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.861855\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's auc: 0.855839\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.84834\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.863325\n",
      "Train until valid scores didn't improve in 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.856973\n",
      "\n",
      "306 features with zero importance after one-hot encoding.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fs.identify_zero_importance(task = 'classification', \n",
    " eval_metric = 'auc', \n",
    " n_iterations = 10, \n",
    " early_stopping = True)\n",
    "# list of zero importance features\n",
    "zero_importance_features = fs.ops['zero_importance']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['collinear', 'zero_importance'] methods have been run\n",
      "\n",
      "Removed 359 features.\n"
     ]
    }
   ],
   "source": [
    "train_removed_all = fs.remove(methods = 'all')\n",
    "columns=list(train_removed_all.columns)\n",
    "columns.append('USRID')\n",
    "columns.append('FLAG')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "train=data[data['FLAG']!=-1]\n",
    "test = data[data['FLAG']==-1]\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "import scipy as sp\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "train.fillna(-1,inplace=True)\n",
    "for rnd in [100]:   \n",
    "    train_x = train.drop(['USRID', 'FLAG'], axis=1).values\n",
    "    train_y = train['FLAG'].values\n",
    "    auc_list = []\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=3)\n",
    "    for train_index, test_index in skf.split(train_x, train_y):\n",
    "        print('Train: %s | test: %s' % (train_index, test_index))\n",
    "        X_train, X_test = train_x[train_index], train_x[test_index]\n",
    "        y_train, y_test = train_y[train_index], train_y[test_index]\n",
    "    \n",
    "        params = {'booster': 'gbtree',\n",
    "              'objective':'binary:logistic',\n",
    "              'eta': 0.02,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 9,  # 2 3\n",
    "              'silent':1,\n",
    "              'seed':rnd,\n",
    "            'eval_metric':'auc'\n",
    "              }\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_test,y_test)\n",
    "        dvali = xgb.DMatrix(X_test)\n",
    "        model = xgb.train(params, dtrain, evals=[(dtrain,'dtrain'),(dval,'dval'),],early_stopping_rounds=100,verbose_eval=300,num_boost_round=3000)\n",
    "        pred_value = model.predict(dvali)\n",
    "    \n",
    "        pred_value = np.array(pred_value)\n",
    "        pred_value = [ele + 1 for ele in pred_value]\n",
    "    \n",
    "        y_test = np.array(y_test)\n",
    "        y_test = [ele + 1 for ele in y_test]\n",
    "    \n",
    "        fpr, tpr, thresholds = roc_curve(y_test, pred_value, pos_label=2)\n",
    "            \n",
    "        auc = metrics.auc(fpr, tpr)\n",
    "        print('auc value:',auc)\n",
    "        auc_list.append(auc)\n",
    "    \n",
    "    print('validate result:',np.mean(auc_list))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import f1_score\n",
    "import sys\n",
    "import scipy as sp\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd=100\n",
    "data.fillna(-1,inplace=True)\n",
    "train =data[data['FLAG']!=-1]\n",
    "test =data[data['FLAG']==-1]\n",
    "columns=list(train_removed_all.columns)\n",
    "columns.append('USRID')\n",
    "columns.append('FLAG')\n",
    "\n",
    "train=train[columns]\n",
    "test = test[columns]\n",
    "\n",
    "train_x = train.drop(['USRID', 'FLAG'], axis=1).values\n",
    "train_y = train['FLAG'].values\n",
    "dtrain = xgb.DMatrix(train_x, train_y)\n",
    "test_x = test.drop(['USRID','FLAG'],axis=1).values\n",
    "\n",
    "params = {'booster': 'gbtree',\n",
    "              'objective':'binary:logistic',\n",
    "              'eta': 0.02,\n",
    "              'max_depth': 5,  # 4 3\n",
    "              'colsample_bytree': 0.7,#0.8\n",
    "              'subsample': 0.7,\n",
    "              'min_child_weight': 9,  # 2 3\n",
    "              'silent':1,\n",
    "              'seed':rnd,\n",
    "            'eval_metric':'auc'\n",
    "              }\n",
    "dvali = xgb.DMatrix(test_x)\n",
    "model = xgb.train(params, dtrain, evals=[(dtrain,'dtrain'),],verbose_eval=100,num_boost_round=730)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "pred_value = model.predict(dvali)\n",
    "result = test[['USRID']]\n",
    "\n",
    "result['RST'] =pred_value\n",
    "result.to_csv('../submit/7-10-xgb_select_all-test.csv',index=None,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
